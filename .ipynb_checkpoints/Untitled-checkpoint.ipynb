{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d03a3a-ed90-4e37-98c0-7ccf8b7d39f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 13:17:40.440772: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-04 13:17:40.443176: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-04 13:17:40.486463: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-04 13:17:40.487717: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 13:17:41.210511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385b6f2c-658c-443c-bc07-278f1a3389c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN:\n",
    "    def __init__(self, x, y, layers):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        self.optimizer = tf.train.AdamOptimizer()\n",
    "        \n",
    "        self.loss = tf.placeholder(tf.float32, shape=())\n",
    "        self.loss_history = []\n",
    "        \n",
    "        self.f = None\n",
    "        self.u = None\n",
    "        self.u_pred = None\n",
    "        \n",
    "        self.build_graph()\n",
    "        \n",
    "    def initialize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0, num_layers - 1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1, layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "    \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2.0/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = tf.add(tf.matmul(X, weights[0]), biases[0])\n",
    "        H = tf.nn.relu(H)\n",
    "        for l in range(1, num_layers - 2):\n",
    "            H = tf.add(tf.matmul(H, weights[l]), biases[l])\n",
    "            H = tf.nn.relu(H)\n",
    "        Y = tf.add(tf.matmul(H, weights[-1]), biases[-1])\n",
    "        return Y\n",
    "    \n",
    "    def net_u(self, x):\n",
    "        u = self.neural_net(x, self.weights, self.biases)\n",
    "        return u\n",
    "    \n",
    "    def net_f(self, x):\n",
    "        u = self.net_u(x)\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        f = u_xx + u - self.y\n",
    "        return f\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.u = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        self.f = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        \n",
    "        self.u_pred = self.net_u(self.x)\n",
    "        self.f_pred = self.net_f(self.x)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.u - self.u_pred)) + tf.reduce_mean(tf.square(self.f_pred - self.f))\n",
    "        \n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        \n",
    "    def train(self, nIter):\n",
    "        for i in range(nIter):\n",
    "            _, l = self.sess.run([self.train_op, self.loss], feed_dict={self.u: self.u_train, self.f: self.f_train})\n",
    "            self.loss_history.append(l)\n",
    "            \n",
    "    def predict(self, x_star):\n",
    "        u_star = self.sess.run(self.u_pred, feed_dict={self.x: x_star})\n",
    "        f_star = self.sess.run(self.f_pred, feed_dict={self.x: x_star})\n",
    "        return u_star, f_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf249219-33a1-4ec0-ac9e-73e07ff00d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
